nohup python -u -m  training --dataset roman-empire --source critical --epochs 1000 --seed 42 --hid 256 --nlayers 3 --K 10 --patience 200 --lr1 0.01 --lr2 0.5 --wd1 0.00005 --wd2 0.0005 --dpC 0.0 --dpM 0.4  --tau 0.3 --batch 64 --dropout 0.2 > logs/uni-roman-p.log &
# roman-empire,UniFilter,74.90±0.91,3.9314490079879763±0.9060731277749745,"{'dataset': 'roman-empire', 'source': 'critical', 'seed': 51290, 'type': 0, 'epochs': 1000, 'patience': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'model': 'gfk', 'lr1': 0.01, 'lr2': 0.5, 'wd1': 5e-05, 'wd2': 0.0005, 'sole': False, 'dpC': 0.0, 'dpM': 0.4, 'plain': False, 'dev': 0, 'hid': 256, 'nlayers': 3, 'bias': 'none', 'batch': 64, 'K': 10, 'tau': 0.3, 'train_rate': 0.6, 'val_rate': 0.2}",critical

nohup python -u -m  training --dataset chameleon --source critical --seed 42 --type 0 --epochs 1000 --patience 200 --lr 0.01 --weight_decay 0.0005 --dropout 0.2 --model gfk --lr1 0.1 --lr2 0.5 --wd1 0.0 --wd2 0.0001 --sole False --dpC 0.3 --dpM 0.6 --plain False --dev 3 --hid 256 --nlayers 3 --bias bn --batch 64 --K 10 --tau 1.0  > logs/uni-chameleon-p.log &
# chameleon,UniFilter,46.07±4.74,3.1311623811721803±0.49727466593680647,"{'dataset': 'chameleon', 'source': 'critical', 'seed': 42, 'type': 0, 'epochs': 1000, 'patience': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'dropout': 0.2, 'model': 'gfk', 'lr1': 0.1, 'lr2': 0.5, 'wd1': 0.0, 'wd2': 0.0001, 'sole': False, 'dpC': 0.3, 'dpM': 0.6, 'plain': False, 'dev': 3, 'hid': 256, 'nlayers': 3, 'bias': 'bn', 'batch': 64, 'K': 10, 'tau': 1.0, 'train_rate': 0.6, 'val_rate': 0.2}",critical
